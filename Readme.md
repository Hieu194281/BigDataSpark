# About the repo

I started this repo because I wanted to learn PySpark.
However, I also didn't want to use Jupyter notebook as it
is typically the case in the examples I came across. 

Therefore, I started with setting up a spark cluster 
using docker. 

## Running the code

## About the book_data directory
The official repo of the book Data Analysis with Python and
PySpark can be found here:https://github.com/jonesberg/DataAnalysisWithPythonAndPySpark.

I did not include the files from this repo as there are
files larger than 50 MB which is the limit for GitHub. At the
time of writing the repo contains a link to Dropbox which
contains the files. I suggest you download them.

The book_data directory contains some files found on
this repo:
https://github.com/maprihoda/data-analysis-with-python-and-pyspark.
Which is also a repo of someone who read the mentioned book.